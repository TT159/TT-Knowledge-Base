---
date: 2025-06-02
tags:
  - Bias
  - LLM
---

# Main content

==Do LMs exhibit bias towards Western entities in non-English, non-Western languages ?==

Primary Objective:
**To assess whether LMs can appropriately distinguish between Arab and Western entities when prompted by culturally specific contexts**


 We thus **construct a new benchmark, CAMeL** (Cultural Appropriateness Measure Set for LMs), which consists of an extensive list of 20,368 Arab and Western entities extracted from Wikidata and CommonCrawl, covering eight entity types (i.e., person names, food dishes, beverages, clothing items, locations, authors, religious places of worship, and sports clubs), and an associated set of 628 naturally occurring prompts as contexts for those entities.


- Developed **CAMeL**, the first large-scale benchmark for measuring cultural bias in LLMs, containing 628 naturally-occurring prompts from Twitter/X and 20,368 culturally relevant entities (e.g., names, foods, locations).
- Designed two types of prompts: culturally contextualized (Arab-specific) and agnostic (neutral).
- Created a **Cultural Bias Score (CBS)** based on language modelsâ€™ preference for Western vs. Arab entities in text-infilling tasks.
- Evaluated 16 LLMs (monolingual Arabic, multilingual) on tasks including story generation, NER, sentiment analysis, and text infilling.


- Demonstrated that LLMs (even Arabic-specific ones) often prefer Western entities in culturally Arab contexts, with CBS scores of 40â€“65%.
- Identified that training data is a major source of bias; Wikipedia is the most Western-centric.
- Analyzed stereotype presence in story generation, showing negative stereotypes associated with Arab names (e.g., â€œpoor,â€ â€œmodestâ€).
- Showed that prompt adaptation (N-shot demos) can reduce bias, while culture tokens have minimal effect.

 we discuss that the prevalence of Western content in Arabic corpora may be **a key contributor** to the observed biases in LMs.
æˆ‘ä»¬è®¨è®ºäº†é˜¿æ‹‰ä¼¯è¯­è¯­æ–™åº“ä¸­è¥¿æ–¹å†…å®¹çš„æµè¡Œå¯èƒ½æ˜¯è§‚å¯Ÿåˆ°çš„è¯­è¨€æ¨¡å‹åå·®çš„å…³é”®å› ç´ ã€‚

## Background

 Truly multicultural LMs should not only communicate across languages but do so with an awareness of cultural sensitivities, fostering a deeper global connection.

much less work (Â§2) has examined the **cultural appropriateness** of LMs in the non-Western and non-English environments.

 There is **no resource** readily available for doing so, especially one that can contrast Arab vs. Western cultural differences


## Construction of CAMeL

starting by collecting entities that exhibit cultural variation. ä»æ”¶é›†è¡¨ç°å‡ºæ–‡åŒ–å·®å¼‚çš„å®ä½“å¼€å§‹


then obtain prompts from Twitter/X data as natural contexts for these entities, which enable various testing setups for measuring cultural biases in LMs
éšåï¼Œä»Twitter/Xæ•°æ®ä¸­è·å–æç¤ºä½œä¸ºè¿™äº›å®ä½“çš„è‡ªç„¶ä¸Šä¸‹æ–‡ï¼Œè¿™ä½¿å¾—èƒ½å¤Ÿé€šè¿‡å„ç§æµ‹è¯•è®¾ç½®æ¥è¡¡é‡è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡åŒ–åè§ã€‚

### Step 1ï¼š Collect Entities

#### Source 1: Entity Extraction from Wikidata

- ç ”ç©¶è€…é¦–å…ˆç¡®å®šäº†8ç±»æ–‡åŒ–ç›¸å…³çš„å®ä½“ï¼ˆåŒ…æ‹¬äººåã€é£Ÿç‰©ã€é¥®å“ã€æœé¥°ã€åœ°ç‚¹ã€ä½œå®¶ã€å®—æ•™åœºæ‰€ã€ä½“è‚²ä¿±ä¹éƒ¨ï¼‰ã€‚
    
- é€šè¿‡åœ¨ **Wikidata** ä¸­æœç´¢è¿™äº›å®ä½“ç±»å‹çš„ç±»åˆ«ï¼ˆä¾‹å¦‚â€œfoodâ€ã€â€œcityâ€ã€â€œdrinkâ€ç­‰ï¼‰ï¼Œæå–æ‰€æœ‰ç”¨é˜¿æ‹‰ä¼¯è¯­æ ‡æ³¨çš„å®ä½“ã€‚
    
- å¯¹äºâ€œåœ°ç‚¹â€ã€â€œä½œå®¶â€å’Œâ€œä½“è‚²ä¿±ä¹éƒ¨â€ç­‰å®ä½“ï¼Œç”±äºåœ¨Wikidataä¸­å¾€å¾€å¸¦æœ‰å›½åˆ«ä¿¡æ¯ï¼Œå› æ­¤å¯ä»¥ç›´æ¥åŒºåˆ†é˜¿æ‹‰ä¼¯æˆ–è¥¿æ–¹æ–‡åŒ–ï¼ˆé˜¿æ‹‰ä¼¯ä¸–ç•Œã€è¥¿æ¬§å’ŒåŒ—ç¾ï¼‰ã€‚

However, for other entity types, we had to manually classify them into Arab and Western lists due to the lack of such demographic labels
- ä½†æ˜¯ï¼Œå¯¹äºå…¶ä»–ç±»åˆ«ï¼ˆå¦‚é¥®å“ã€è¡£æœç­‰ï¼‰ï¼Œç”±äºç¼ºä¹æ˜¾å¼çš„æ–‡åŒ–æ ‡ç­¾ï¼Œåªèƒ½æ‰‹åŠ¨å¯¹å…¶è¿›è¡Œåˆ†ç±»ï¼ˆé˜¿æ‹‰ä¼¯ vs. è¥¿æ–¹ï¼‰ã€æ³¨ï¼šä½œè€…åœ¨é™„å½•B.1ä¸­æä¾›äº†æ›´å¤šç»†èŠ‚ã€‘ã€‚
    
- éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒWikidataå¯¹åœ°ç‚¹ã€ä½“è‚²ä¿±ä¹éƒ¨å’Œä½œå®¶çš„è¦†ç›–è¾ƒå¥½ï¼Œä½†å¯¹å…¶ä»–å®ä½“çš„è¦†ç›–ç›¸å¯¹æœ‰é™ã€‚


#### Source 2: Entity Extraction from Web Crawls. (Arabic subset of CommonCrawl corpus)

- ä¸ºäº†å¼¥è¡¥ Wikidata è¦†ç›–ä¸è¶³çš„é—®é¢˜ï¼Œç ”ç©¶è€…åˆåˆ©ç”¨äº† **CommonCrawl çš„é˜¿æ‹‰ä¼¯è¯­å­é›†**ã€‚

 For each entity type, we manually design 5 to 10 generic patterns composed of nouns or noun-verb expressions typically followed by a specific entity
- è¿™é‡Œä½¿ç”¨äº† **æ¨¡å¼åŒ¹é…** çš„æ–¹æ³•ï¼ˆpattern-based extractionï¼‰ï¼Œå³ä½¿ç”¨ä¸€æ‰¹ï¼ˆ5-10æ¡ï¼‰æ‰‹å·¥è®¾è®¡çš„æ¨¡å¼ï¼ˆä¸€èˆ¬ç”±åè¯æˆ–åŠ¨è¯-åè¯çŸ­è¯­æ„æˆï¼‰æ¥æå–å®ä½“ã€‚
    
    - ä¾‹å¦‚ï¼šâ€œsister named â€¦â€ è¿™æ ·çš„æ¨¡å¼å¯ä»¥æå–åˆ°äººåã€‚ is likely to be followed by a female name.
        
    - ç ”ç©¶è€…è¿˜å¯¹è¿™äº›æ¨¡å¼è¿›è¡Œäº† **é˜¿æ‹‰ä¼¯è¯­çš„æ€§åˆ«å’Œæ•°çš„å˜ä½**ï¼Œä»¥é€‚åº”é˜¿æ‹‰ä¼¯è¯­çš„è¯­æ³•ç‰¹æ€§ã€‚
    - åœ¨é˜¿æ‹‰ä¼¯è¯­ä¸­ï¼ŒåŠ¨è¯çš„å˜ä½åæ˜ äº†ä¸»è¯­çš„æ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼‰å’Œæ•°ï¼ˆå•æ•°ã€åŒæ•°æˆ–å¤æ•°ï¼‰ã€‚
        
- åŒ¹é…æ—¶åªæå–æ¨¡å¼åé¢æœ€å¤š2ä¸ªè¯ï¼Œä»¥ä¿è¯å¬å›ç‡ï¼ˆå³æ‰¾åˆ°æ›´å¤šå®ä½“ï¼‰ï¼Œè€Œä¸å±€é™äºç²¾ç¡®çš„é•¿å¥ã€‚
    
- è¿™æ ·ï¼Œæ¯ä¸ªç±»åˆ«å¤§æ¦‚èƒ½æå–åˆ° **5000åˆ°10000æ¡å®ä½“**ï¼Œç„¶åå†ç»è¿‡äººå·¥ç­›é€‰å’Œæ³¨é‡Šï¼Œç¡®ä¿é«˜å‡†ç¡®ç‡ã€‚
    
- åŒæ—¶ï¼Œå¯¹äººåå’Œæœé¥°ç­‰å®ä½“æ ¹æ®æ€§åˆ«è¿›è¡Œåˆ†ç±»ï¼ˆç¬¦åˆé˜¿æ‹‰ä¼¯è¯­çš„æ€§åˆ«è¯­æ³•ç‰¹å¾ï¼‰ï¼Œä½†ä½œè€…ç‰¹åˆ«è¯´æ˜è¿™å¹¶éä¸ºäº†æ’æ–¥å…¶ä»–æ€§åˆ«èº«ä»½ï¼Œè€Œæ˜¯å‡ºäºè¯­è¨€ç»“æ„çš„è€ƒè™‘ã€‚
 We split name and clothing entities into male/female categories to match Arabicâ€™s gendered grammar, without intending to exclude other gender identities

é‡‡ç”¨pattern-matchingçš„æ–¹æ³•ï¼Œè¿™å¯ä»¥é¿å… using any LMs in the construction of the dataset that will be used for evaluating LMs

æ­¤å¤–ï¼Œ We avoid using more specific and longer patterns to ensure wider coverage of entities (i.e., higher recall lower precision). æˆ‘ä»¬é¿å…ä½¿ç”¨æ›´å…·ä½“å’Œæ›´é•¿çš„æ¨¡å¼ï¼Œä»¥ç¡®ä¿å®ä½“çš„å¹¿æ³›è¦†ç›–ï¼ˆå³ï¼Œæ›´é«˜çš„å¬å›ç‡å’Œæ›´ä½çš„ç²¾ç¡®åº¦ï¼‰ã€‚

æ¨¡å¼è¶Šé•¿ï¼Œè¢«åŒ¹é…çš„å€™é€‰è€…å°±è‚¯å®šè¶Šå°‘å˜›ã€‚åœ¨åšæ¨¡å¼åŒ¹é…æå–å®ä½“æ—¶ï¼Œä»–ä»¬åˆ»æ„é¿å…ç”¨è¿‡äºå…·ä½“å’Œå¤ªé•¿çš„æ¨¡å¼ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº† **å°½å¯èƒ½å¤šåœ°æå–å‡ºå€™é€‰å®ä½“ï¼ˆé«˜å¬å›ç‡ï¼‰**ï¼Œå³å®å¯å¤šæŠ“ä¸€äº›å™ªéŸ³ï¼ˆä¸ç²¾å‡†ï¼Œä¹Ÿå°±æ˜¯precisionä¼šé™ä½ï¼‰å®ä½“ï¼Œä¹Ÿä¸æƒ³æ¼æ‰é‚£äº›å¯èƒ½ç›¸å…³çš„å®ä½“ã€‚

ä¾‹å­ï¼š
å‡è®¾è¦æå–äººåï¼Œå¦‚æœç”¨çš„æ¨¡å¼æ˜¯ï¼š
- å¤ªå…·ä½“çš„æ¨¡å¼ï¼šâ€œØ£Ù†Ø§ Ø±Ø£ÙŠØª Ø£Ø®ØªÙŠ Ø§Ù„Ù…Ø³Ù…Ø§Ø© ...â€ï¼ˆæˆ‘çœ‹åˆ°äº†æˆ‘å¦¹å¦¹ï¼Œåå­—å«â€¦â€¦ï¼‰ï¼Œ  
    â†’ è¿™å¯èƒ½åªæå–åˆ°å¾ˆå°‘çš„åå­—ï¼Œå› ä¸ºä¸Šä¸‹æ–‡å¿…é¡»ä¸¥æ ¼ç¬¦åˆâ€œæˆ‘å¦¹å¦¹ï¼Œåå­—å«â€¦â€¦â€ã€‚

- æ›´å®½æ³›çš„æ¨¡å¼ï¼šâ€œØ§Ø³Ù…Ù‡Ø§ ...â€ï¼ˆå¥¹çš„åå­—æ˜¯â€¦â€¦ï¼‰ï¼Œ  
    â†’ è¿™å¯ä»¥è¦†ç›–æ›´å¤šçš„è¯­å¢ƒï¼Œä¹Ÿè®¸æå–åˆ°æ›´å¤šçš„äººåï¼Œè™½ç„¶æœ‰äº›å¯èƒ½æ˜¯å™ªéŸ³ï¼Œâ€å¥¹çš„åå­—æ˜¯çˆ·çˆ·èµ·çš„â€œï¼Œæå–åˆ°çš„patternåé¢çš„ä¸¤ä¸ªè¯å°±ä¼šæ˜¯â€çˆ·çˆ·â€œï¼Œè€Œä¸æ˜¯åå­—ã€‚
    
- è¿™æ ·åšçš„å¥½å¤„ï¼šèƒ½æå–åˆ°æ›´å¤šæ½œåœ¨çš„å®ä½“ï¼Œä¿è¯æ•°æ®é›†çš„è¦†ç›–ç‡ã€‚
- ä¸è¶³ä¹‹å¤„ï¼šå¯èƒ½ä¼šåŒ…å«ä¸€äº›é”™è¯¯æˆ–å™ªéŸ³ï¼ˆprecision ä¸‹é™ï¼‰ã€‚

è¿™ç§åšæ³•ç¬¦åˆä¿¡æ¯æå–çš„å¸¸è§ç­–ç•¥ï¼š**å…ˆä¿è¯é«˜å¬å›ï¼ˆæŠŠå°½å¯èƒ½å¤šçš„ä¸œè¥¿æŠ“å›æ¥ï¼‰ï¼Œåç»­å¯ä»¥é€šè¿‡äººå·¥ç­›é€‰æˆ–è€…åå¤„ç†æé«˜ç²¾ç¡®ç‡**ã€‚

### Step 2: Obtain Prompt 

To assess whether LMs can appropriately distinguish between Arab and Western entities when prompted by culturally specific contexts
æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡ä¹‹ä¸€æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šæ–‡åŒ–èƒŒæ™¯ä¸‹æ˜¯å¦èƒ½å¤Ÿæ°å½“åœ°åŒºåˆ†é˜¿æ‹‰ä¼¯å®ä½“å’Œè¥¿æ–¹å®ä½“ã€‚

 To ensure we evaluate LMs in scenarios that mirror actual language uses, we construct our prompts from natural contexts that we retrieve from Twitter/X, rather than crowdsourcing prompts
ä¸ºäº†ç¡®ä¿æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿå®é™…è¯­è¨€ä½¿ç”¨çš„åœºæ™¯ä¸­è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬ä»Twitter/Xä¸­æ£€ç´¢çš„è‡ªç„¶è¯­å¢ƒæ„å»ºæç¤ºï¼Œè€Œä¸æ˜¯ä¼—åŒ…æ’°å†™çš„æç¤ºã€‚

#### Prompt Types
##### Prompt Type 1: culturally-contextualized prompts (CAMeL-Co)
==Create prompts that embed an Arab cultural reference==
æ‰€ä»¥éœ€è¦åˆ›å»ºå«æœ‰Arabæ–‡åŒ–å‚è€ƒçš„prompts

**Arbaræ–‡åŒ–æç¤ºï¼ˆCAMeL-Coï¼‰**ï¼šåŒ…å«é˜¿æ‹‰ä¼¯æ–‡åŒ–å…ƒç´ çš„æç¤ºï¼Œä¸“é—¨ç”¨äºæµ‹è¯•æ¨¡å‹åœ¨é˜¿æ‹‰ä¼¯æ–‡åŒ–ä¸Šä¸‹æ–‡ä¸‹çš„

To achieve this, we create prompts that embed an Arab cultural reference, ensuring they provide contexts uniquely suited for Arab entities
ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬åˆ›å»ºäº†åŒ…å«é˜¿æ‹‰ä¼¯æ–‡åŒ–å‚è€ƒçš„æç¤ºï¼Œç¡®ä¿å®ƒä»¬ä¸ºé˜¿æ‹‰ä¼¯å®ä½“æä¾›ç‹¬ç‰¹çš„ä¸Šä¸‹æ–‡ã€‚

This allows to gauge the LMâ€™s cultural adaptation ability.

we created 250 CAMeL-Co prompts by replacing the original context entities with a [MASK] token

##### Prompt Type 2: culturally-agnostic prompts (CAMeL-Ag)

**ä¸­ç«‹æç¤ºï¼ˆCAMeL-Agï¼‰**ï¼šä¸å¸¦ä»»ä½•æ–‡åŒ–èƒŒæ™¯çš„æç¤ºï¼Œç”¨æ¥æ£€æµ‹æ¨¡å‹é»˜è®¤çš„æ–‡åŒ–å€¾å‘ã€‚

 we create prompts with neutral contexts, enabling us to determine the default cultural leanings of LMs.
æˆ‘ä»¬åˆ›å»ºä¸­æ€§è¯­å¢ƒçš„æç¤ºï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç¡®å®šLMsçš„é»˜è®¤æ–‡åŒ–å€¾å‘ã€‚


 we constructed 378 prompts for CAMeL-Ag using generic patterns as search queries that do not contain any cultural reference

#### How to do

 We employ **two keyword search strategies** to retrieve tweets that reflect an Arab cultural context for each entity category.

##### 1ï¸âƒ£ æ£€ç´¢è‡ªç„¶ä¸Šä¸‹æ–‡ï¼ˆRetrieving Natural Contextsï¼‰

- **æ•°æ®æ¥æº**ï¼šä¸ºäº†ä¿è¯æç¤ºçš„â€œçœŸå®æ€§â€ï¼Œç ”ç©¶è€…ä»ç¤¾äº¤åª’ä½“ **Twitter/X** ä¸ŠæŠ“å–çœŸå®ç”¨æˆ·çš„æ¨æ–‡ï¼Œè€Œä¸æ˜¯é€šè¿‡äººå·¥ä¼—åŒ…æˆ–è®©è¯­è¨€æ¨¡å‹è‡ªå·±ç”Ÿæˆã€‚
    
- **æ£€ç´¢ç­–ç•¥**ï¼š
    - **å…³é”®è¯æ³•**ï¼šä»ä½œè€…å‡†å¤‡çš„é˜¿æ‹‰ä¼¯å®ä½“åˆ—è¡¨ä¸­éšæœºæŠ½å–20ä¸ªè¯ï¼ˆä¾‹å¦‚é£Ÿç‰©ã€åœ°åã€è¡£æœç­‰ï¼‰ï¼Œä½œä¸ºå…³é”®è¯è¿›è¡Œæœç´¢ï¼Œæ•æ‰åŒ…å«è¿™äº›æ–‡åŒ–å®ä½“çš„æ¨æ–‡ã€‚
	     we use 20 randomly sampled Arab entities from our lists as search queries to capture discussions about culturally-relevant entities.
        
    - **æ¨¡å¼æ³•**ï¼šæ‰‹å·¥è®¾è®¡1-2ä¸ªæè¿°é˜¿æ‹‰ä¼¯æ–‡åŒ–å®ä½“çš„å½¢å®¹è¯çŸ­è¯­ï¼ˆå¦‚â€œby the Arab authorâ€ç­‰ï¼‰ï¼Œè¿›ä¸€æ­¥ç²¾å‡†æœç´¢æ¨æ–‡ä¸­çš„é˜¿æ‹‰ä¼¯æ–‡åŒ–ä¸Šä¸‹æ–‡ã€‚
	     We further refine our search using one or two manually-designed patterns of adjective phrases that directly reference an Arab entity
        
- **æ—¶é—´èŒƒå›´**ï¼šæ£€ç´¢çš„æ¨æ–‡æ—¶é—´é™å®šåœ¨2023å¹´8æœˆ1æ—¥è‡³9æœˆ30æ—¥ä¹‹é—´ï¼Œç›®çš„æ˜¯é¿å…LMçš„è®­ç»ƒæ•°æ®é‡Œå·²ç»åŒ…å«äº†è¿™äº›å†…å®¹ï¼Œç¡®ä¿æµ‹è¯•å…¬å¹³ã€‚

å› ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰æ˜¯åœ¨å¤§é‡æ•°æ®ä¸Šé¢„è®­ç»ƒçš„ï¼Œè€Œå¤§éƒ¨åˆ†æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸€èˆ¬éƒ½ä¼šåœ¨æŸä¸ªæ—¶é—´ç‚¹ä¹‹å‰æ”¶é›†å¥½ï¼Œæ¯”å¦‚åˆ°2023å¹´åˆæˆ–æ›´æ—©ã€‚
å¦‚æœCAMeLæ•°æ®ä¸­çš„æç¤ºæ˜¯åœ¨2023å¹´8æœˆä»¥åæ‰æ”¶é›†çš„ï¼Œé‚£è¿™äº›æ¨æ–‡å°±**å¾ˆå¯èƒ½æ²¡è¢«æ¨¡å‹è§è¿‡**ã€‚
è¿™å°±èƒ½ä¿è¯æµ‹è¯•æ—¶æ¨¡å‹æ²¡è§è¿‡è¿™äº›å…·ä½“å¥å­ï¼Œä»è€Œé¿å…äº†â€œæ•°æ®æ³„æ¼â€ï¼Œæ¨¡å‹æ— æ³•â€œèƒŒç­”æ¡ˆâ€æˆ–è€…å› ä¸ºè®°å¿†è€Œè¡¨ç°å¾—è¿‡å¥½ã€‚

è¿™å°±æ˜¯â€œå…¬å¹³â€çš„å«ä¹‰ï¼š
- è®©æ¨¡å‹é¢å¯¹æ–°é—®é¢˜ï¼Œè€Œä¸æ˜¯æ—§é—®é¢˜ï¼ˆå³å®ƒæ²¡åœ¨è®­ç»ƒæ—¶å°±å­¦è¿‡ï¼‰ã€‚
- è¿™æ ·æµ‹å‡ºæ¥çš„æ•ˆæœæ‰åæ˜ æ¨¡å‹çš„çœŸå®æ³›åŒ–èƒ½åŠ›ï¼Œè€Œä¸æ˜¯çœ‹å®ƒèƒ½ä¸èƒ½è®°ä½è®­ç»ƒæ•°æ®ã€‚

##### 2ï¸âƒ£ ç”Ÿæˆæç¤º prompt generate

- **æ–‡åŒ–åŒ–æç¤ºï¼ˆCAMeL-Coï¼‰**ï¼šåœ¨æ¨æ–‡ä¸­æ‰¾åˆ°åŒ…å«é˜¿æ‹‰ä¼¯æ–‡åŒ–å®ä½“çš„å¥å­ï¼Œç„¶åå°†å…¶ä¸­çš„å®ä½“æ›¿æ¢æˆ `[MASK]` ä½œä¸ºå¡«ç©ºæç¤ºã€‚è¿™æ ·ï¼Œæ¨¡å‹éœ€è¦åœ¨ç»™å®šçš„æ–‡åŒ–ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆç­”æ¡ˆã€‚
    
    - ä¾‹å¦‚ï¼šæ¨æ–‡â€œæˆ‘å’Œæœ‹å‹åœ¨ä¼Šæ–¯å…°ç¥·å‘Šåå»å–[æŸç§é¥®å“]â€ï¼Œå¯ä»¥ç”Ÿæˆâ€œæˆ‘å’Œæœ‹å‹åœ¨ä¼Šæ–¯å…°ç¥·å‘Šåå»å– [MASK]â€ã€‚
        
- **ä¸­ç«‹æç¤ºï¼ˆCAMeL-Agï¼‰**ï¼šåŒæ ·ä»æ¨æ–‡é‡Œæå–ï¼Œä½†è¿™äº›å¥å­ä¸­ä¸åŒ…å«æ˜æ˜¾çš„æ–‡åŒ–ä¿¡æ¯ï¼Œç”¨ä½œå¯¹æ¯”å®éªŒã€‚


##### ğŸ“ æƒ…æ„Ÿæ ‡æ³¨ï¼ˆSentiment Annotationï¼‰

- ä¸ºäº†åç»­è¯„ä¼°æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æï¼ˆSentiment Analysisï¼‰ä»»åŠ¡ä¸Šçš„å…¬å¹³æ€§ï¼Œè¿™äº›æç¤ºä¹Ÿè¢«äººå·¥æ ‡æ³¨ä¸º **æ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§**ã€‚
- æ ‡æ³¨è€…ä¹‹é—´çš„ä¸€è‡´æ€§éå¸¸é«˜ï¼ˆCohenâ€™s Kappa = 0.954ï¼‰ï¼Œè¯´æ˜æ•°æ®è´¨é‡å¯é ã€‚

è¿™æ˜¯ä¸ºäº†â€œæƒ…æ„Ÿåˆ†æâ€ä»»åŠ¡æœåŠ¡çš„ã€‚å› ä¸ºCAMeLä¸ä»…ç”¨æ¥æµ‹é‡æ¨¡å‹åœ¨æ•…äº‹ç”Ÿæˆæˆ–NERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰ä¸Šçš„æ–‡åŒ–åè§ï¼Œè¿˜å¸Œæœ›æµ‹é‡åœ¨â€œæƒ…æ„Ÿåˆ†æâ€ä»»åŠ¡ï¼ˆä¹Ÿå°±æ˜¯åˆ¤å®šä¸€å¥è¯æ˜¯æ­£é¢ã€è´Ÿé¢è¿˜æ˜¯ä¸­æ€§ï¼‰ä¸Šï¼Œæ¨¡å‹å¯¹ä¸åŒæ–‡åŒ–èƒŒæ™¯çš„è¡¨ç°æ˜¯å¦å…¬å¹³ã€‚

ä¸ºä»€ä¹ˆè¦æ ‡æ³¨ï¼Ÿ**æ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§**ï¼š
    - æ­£é¢ï¼šè¡¨è¾¾äº†ç§¯æã€èµæ‰¬ã€æ„‰å¿«çš„æƒ…ç»ªã€‚
    - è´Ÿé¢ï¼šè¡¨è¾¾äº†æ¶ˆæã€æ‰¹è¯„ã€æ„¤æ€’çš„æƒ…ç»ªã€‚
    - ä¸­æ€§ï¼šä¸å¸¦æƒ…ç»ªè‰²å½©ï¼Œä»…é™ˆè¿°äº‹å®ã€‚
        

é€šè¿‡äººå·¥æ ‡æ³¨ï¼Œç¡®ä¿æµ‹è¯•é›†çš„æƒ…æ„Ÿæ ‡ç­¾æ˜¯çœŸå®ä¸”ä¸€è‡´çš„ï¼Œè¿™æ ·è¯„ä¼°æ¨¡å‹çš„æ—¶å€™å°±èƒ½ï¼š  
ç›´æ¥æ¯”è¾ƒæ¨¡å‹å¯¹å«æœ‰é˜¿æ‹‰ä¼¯å®ä½“å’Œè¥¿æ–¹å®ä½“çš„å¥å­é¢„æµ‹çš„æƒ…æ„Ÿæ ‡ç­¾ï¼Œçœ‹å®ƒæ˜¯å¦å­˜åœ¨åå‘ï¼ˆæ¯”å¦‚æ¨¡å‹æ˜¯ä¸æ˜¯æ›´å®¹æ˜“å°†å«é˜¿æ‹‰ä¼¯å®ä½“çš„å¥å­åˆ¤ä¸ºè´Ÿé¢ï¼‰ã€‚

å¦‚æœæ¨¡å‹å¯¹åŒæ ·çš„å¥å­ï¼ˆç»“æ„å’Œå«ä¹‰ï¼‰åœ¨é‡åˆ°é˜¿æ‹‰ä¼¯å®ä½“æ—¶æ›´å€¾å‘äºæ‰“è´Ÿé¢æ ‡ç­¾ï¼Œè€Œé‡åˆ°è¥¿æ–¹å®ä½“å°±æ‰“æ­£é¢æ ‡ç­¾ï¼Œè¿™å°±è¯´æ˜æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æä¸Šä¹Ÿå­˜åœ¨æ–‡åŒ–åè§ã€‚å› æ­¤ï¼Œæƒ…æ„Ÿæ ‡æ³¨å¯ä»¥å¸®åŠ©æ£€æµ‹å¹¶é‡åŒ–è¿™ç§æ½œåœ¨çš„æ–‡åŒ–ä¸å…¬å¹³ã€‚

==å®é™…ä¸Šï¼Œå°±æ˜¯åœ¨åšæƒ…æ„Ÿåˆ†æä»»åŠ¡æ—¶ï¼Œæœ‰äº†ground truth==


## Experiment: Measuring Bias

### Cultural Stereotypes in Story Generation
we analyze the frequency of adjective usage by LMs in the stories featuring Arab or Western names. To do so, we extract all adjectives from stories using the Farasa POS tagger (Abdelali et al., 2016) and compute their Odds Ratio (OR) (Wan et al., 2023)

A large OR indicates more odds for an adjective of appearing in Western stories, while a small OR indicates more odds of appearing in Arab ones.

We inspect adjectives with the 50 highest and lowest ORs to identify and categorize adjectives that reflect stereotypes based on the work of Cao et al. (2022a), which outlines descriptive adjectives for stereotypical traits (e.g., poor, likeable, etc.) using the Agency-Belief Communion (ABC) framework (Koch et al., 2016).

é€šè¿‡å¯¹æ¯”åˆ†æç”Ÿæˆæ•…äº‹é‡Œçš„å½¢å®¹è¯ï¼Œç»“åˆORæŒ‡æ ‡å’ŒABCæ¡†æ¶ï¼Œæ¥é‡åŒ–å’Œæ­ç¤ºè¯­è¨€æ¨¡å‹åœ¨æ–‡åŒ–ä¸Šçš„æ½œåœ¨åˆ»æ¿å°è±¡ï¼ˆåè§ï¼‰ã€‚  

Stories about Arab characters more often cover a theme of poverty with adjectives such as â€œpoorâ€ persistently used across LMs

- ä¸åŒæ¨¡å‹ï¼ˆJAIS-Chatã€GPT-3.5ã€GPT-4ï¼‰éƒ½å±•ç°å‡ºç±»ä¼¼çš„å€¾å‘ã€‚
    
- æ¨¡å‹å¾€å¾€æŠŠé˜¿æ‹‰ä¼¯åå­—çš„æ•…äº‹å¼€å¤´å†™æˆâ€œç”Ÿäºè´«å›°ã€è°¦é€Šçš„å®¶åº­â€ï¼Œè€Œåœ¨è¥¿æ–¹åå­—çš„æ•…äº‹é‡Œåˆ™æ›´å®¹æ˜“å†™æˆâ€œå¯Œæœ‰ã€å“è¶Šâ€ç­‰é«˜åœ°ä½å½¢è±¡ã€‚

è¿™æ®µåˆ†æè¯´æ˜GPTç±»æ¨¡å‹åœ¨â€œè®²æ•…äº‹â€ä»»åŠ¡ä¸­å­˜åœ¨æ½œåœ¨çš„æ–‡åŒ–åè§ã€‚  
æ¨¡å‹åœ¨æ¶‰åŠé˜¿æ‹‰ä¼¯äººç‰©æ—¶æ›´å€¾å‘äºä½¿ç”¨â€œpoorâ€ã€â€œmodestâ€ç­‰è´Ÿé¢æˆ–ä¼ ç»Ÿçš„å½¢å®¹è¯ï¼Œè€Œåœ¨æ¶‰åŠè¥¿æ–¹äººç‰©æ—¶åˆ™æ›´å€¾å‘äºâ€œwealthyâ€ã€â€œpopularâ€ç­‰æ­£é¢å½¢å®¹è¯ã€‚  
é€šè¿‡ORå’ŒABCæ¡†æ¶é‡åŒ–è¿™ç§åè§ï¼Œä¸ºæ¨¡å‹å…¬å¹³æ€§æ”¹è¿›æä¾›äº†å®¢è§‚ä¾æ®ã€‚


### Fairness in NER and Sentiment Analysis

We leverage culturally-contextualized prompts (CAMeL-Co) which have been manually labelled for sentiment (Â§3.2) to create the test data. Specifically, for each of the prompts, we replace the [MASK] token with 50 randomly sampled Arab and Western entities. 
æˆ‘ä»¬åˆ©ç”¨æ–‡åŒ–è¯­å¢ƒåŒ–çš„æç¤ºï¼ˆCAMeL-Coï¼‰ï¼Œè¿™äº›æç¤ºå·²æ‰‹åŠ¨æ ‡æ³¨æƒ…æ„Ÿï¼ˆç¬¬3.2èŠ‚ï¼‰ï¼Œä»¥ç”Ÿæˆæµ‹è¯•æ•°æ®ã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹äºæ¯ä¸ªæç¤ºï¼Œæˆ‘ä»¬å°†[MASK]æ ‡è®°æ›¿æ¢ä¸º50ä¸ªéšæœºé€‰å–çš„é˜¿æ‹‰ä¼¯å’Œè¥¿æ–¹å®ä½“ã€‚(è¿™æ ·å¯ä»¥ç›´æ¥æ¯”è¾ƒæ¨¡å‹åœ¨ä¸åŒæ–‡åŒ–å®ä½“ä¸‹çš„è¡¨ç°ã€‚)

å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä¸æƒ…æ„Ÿåˆ†æï¼ˆSentiment Analysisï¼‰ä¸­çš„å…¬å¹³æ€§

**è¿™éƒ¨åˆ†çš„ç›®çš„æ˜¯æ£€éªŒæ¨¡å‹åœ¨è¿™ä¸¤ä¸ªä»»åŠ¡ä¸Šæ˜¯å¦å¯¹â€œé˜¿æ‹‰ä¼¯å®ä½“â€å’Œâ€œè¥¿æ–¹å®ä½“â€è¡¨ç°å…¬å¹³ã€‚**

- **NERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰**ï¼šä»æ–‡æœ¬ä¸­è¯†åˆ«äººåã€åœ°åç­‰ä¿¡æ¯ã€‚
    
- **Sentiment Analysisï¼ˆæƒ…æ„Ÿåˆ†æï¼‰**ï¼šåˆ¤æ–­å¥å­è¡¨è¾¾çš„æ˜¯æ­£é¢ã€è´Ÿé¢è¿˜æ˜¯ä¸­æ€§æƒ…ç»ªã€‚

 We create models capable of performing Arabic NER and sentiment prediction by fine-tuning LMs on datasets commonly used in Arabic NLU benchmarks.
 æˆ‘ä»¬é€šè¿‡åœ¨å¸¸ç”¨çš„é˜¿æ‹‰ä¼¯è¯­NLUåŸºå‡†æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå®Œæˆé˜¿æ‹‰ä¼¯è¯­NERå’Œæƒ…æ„Ÿé¢„æµ‹ä»»åŠ¡ã€‚
- **ANERCorp**ï¼šé˜¿æ‹‰ä¼¯è¯­NERæ•°æ®é›†
- **HARD**ï¼šé˜¿æ‹‰ä¼¯è¯­æƒ…æ„Ÿåˆ†ææ•°æ®é›†

Task 1, NER:
We find that most LMs perform better when tagging Western person names and locations.
Larger discrepancies are observed on locations, reaching up to 20 F1 points of difference.
æˆ‘ä»¬å‘ç°å¤§å¤šæ•°æ¨¡å‹åœ¨æ ‡æ³¨è¥¿æ–¹äººåå’Œåœ°ç‚¹æ—¶è¡¨ç°æ›´å¥½ã€‚åœ°ç‚¹æ ‡ç­¾çš„å·®è·æ›´å¤§ï¼Œæœ€é«˜å¯è¾¾20ä¸ªF1ç‚¹çš„å·®å¼‚ã€‚


Task 2, Sentiment analysis:
 we examine differences in false positive and false negative predictions between sentences containing Arab vs. Western entities.
 æˆ‘ä»¬ç ”ç©¶äº†åŒ…å«é˜¿æ‹‰ä¼¯å®ä½“å’Œè¥¿æ–¹å®ä½“çš„å¥å­åœ¨å‡é˜³æ€§å’Œå‡é˜´æ€§é¢„æµ‹ä¸Šçš„å·®å¼‚ã€‚
 
- **å‡é˜³æ€§ï¼ˆFPï¼‰**ï¼šæ¨¡å‹æŠŠä¸­æ€§/è´Ÿé¢å¥å­é”™åˆ¤æˆæ­£é¢ã€‚
- **å‡é˜´æ€§ï¼ˆFNï¼‰**ï¼šæ¨¡å‹æŠŠæ­£é¢å¥å­é”™åˆ¤æˆä¸­æ€§/è´Ÿé¢ã€‚

 We observe that nearly all LMs achieve higher false negatives on sentences containing Arab entities, suggesting more false association of Arab entities with negative sentiment.
æˆ‘ä»¬è§‚å¯Ÿåˆ°å‡ ä¹æ‰€æœ‰æ¨¡å‹åœ¨å«æœ‰é˜¿æ‹‰ä¼¯å®ä½“çš„å¥å­ä¸Šå‡é˜´æ€§æ›´é«˜ï¼Œ**è¡¨æ˜å®ƒä»¬æ›´å®¹æ˜“é”™è¯¯åœ°å°†é˜¿æ‹‰ä¼¯å®ä½“ä¸è´Ÿé¢æƒ…ç»ªè”ç³»èµ·æ¥ã€‚**
è¿™è¯´æ˜æ¨¡å‹å¯¹é˜¿æ‹‰ä¼¯å®ä½“å­˜åœ¨æ½œåœ¨çš„è´Ÿé¢åè§ã€‚

### Culturally-Appropriate Text Infilling

æ–‡åŒ–é€‚åº”æ€§çš„æ–‡æœ¬è¡¥å…¨ä»»åŠ¡  
 we use a likelihood-based score that compares model preference of Western vs. Arab entities as fillings of [MASK] tokens in CAMeL prompts.
è¿™éƒ¨åˆ†ä¸»è¦æ˜¯æ£€éªŒæ¨¡å‹æ˜¯å¦èƒ½æ ¹æ®ç»™å®šçš„æ–‡åŒ–èƒŒæ™¯æç¤ºï¼Œæ­£ç¡®é€‰æ‹©æœ€åˆé€‚çš„é˜¿æ‹‰ä¼¯æˆ–è¥¿æ–¹å®ä½“å¡«å…… `[MASK]`ã€‚


æˆ‘ä»¬ä½¿ç”¨åŸºäºä¼¼ç„¶çš„è¯„åˆ†æ–¹æ³•ï¼Œåˆ›å»ºäº†Cultural Bias Score (CBS)ï¼Œæ¯”è¾ƒæ¨¡å‹åœ¨ `[MASK]` ä¸­æ›´å€¾å‘äºé€‰æ‹©è¥¿æ–¹å®ä½“è¿˜æ˜¯é˜¿æ‹‰ä¼¯å®ä½“ï¼Œä»¥æ­¤æµ‹è¯•æ¨¡å‹çš„æ–‡åŒ–é€‚åº”èƒ½åŠ›ã€‚

**Cultural Bias Score (CBS)**

The CBS computes the percentage of a modelâ€™s preference of Western entities over Arab ones
CBSè®¡ç®—äº†æ¨¡å‹å¯¹è¥¿æ–¹å®ä½“çš„åå¥½è¶…è¿‡é˜¿æ‹‰ä¼¯å®ä½“çš„ç™¾åˆ†æ¯”ã€‚

è¿™æ˜¯æœ¬æ–‡æå‡ºçš„è¡¡é‡æ¨¡å‹æ–‡åŒ–åè§çš„æŒ‡æ ‡ï¼Œè¡¡é‡**æ¨¡å‹åœ¨ç»™å®šæç¤ºä¸‹æ›´å€¾å‘äºé€‰æ‹©è¥¿æ–¹å®ä½“çš„æ¦‚ç‡**ã€‚

- æ•°å­¦è¡¨è¾¾å¼ï¼ˆç®€åŒ–è§£é‡Šï¼‰ï¼š

    - å¯¹äºä¸€ä¸ªæç¤º `tâ‚–` å’Œæ‰€æœ‰çš„é˜¿æ‹‰ä¼¯å®ä½“é›†åˆ `A` åŠè¥¿æ–¹å®ä½“é›†åˆ `B`ï¼Œæ¯”è¾ƒï¼š
        
        - `P[MASK](bâ±¼|tâ‚–)`ï¼ˆè¥¿æ–¹å®ä½“çš„æ¦‚ç‡ï¼‰
        - `P[MASK](aáµ¢|tâ‚–)`ï¼ˆé˜¿æ‹‰ä¼¯å®ä½“çš„æ¦‚ç‡ï¼‰
    - å¦‚æœè¥¿æ–¹å®ä½“çš„æ¦‚ç‡å¤§äºé˜¿æ‹‰ä¼¯å®ä½“ï¼Œå°±åŠ 1ã€‚
        
    - æœ€åï¼Œå¯¹æ‰€æœ‰ç»„åˆåšå¹³å‡ï¼Œå¾—åˆ° `CBS âˆˆ [0,1]`ï¼Œä¹˜ä»¥100%è¡¨ç¤ºåå‘è¥¿æ–¹çš„æ¯”ä¾‹ã€‚

- CBSæ¥è¿‘100%è¡¨ç¤ºæ¨¡å‹æ€»æ˜¯åå‘è¥¿æ–¹å®ä½“ï¼ˆä¸¥é‡è¥¿æ–¹åè§ï¼‰ã€‚
- CBSæ¥è¿‘0%è¡¨ç¤ºæ¨¡å‹å‡ ä¹æ€»æ˜¯é€‰æ‹©é˜¿æ‹‰ä¼¯å®ä½“ï¼ˆç†æƒ³æƒ…å†µä¸‹ï¼Œç¬¦åˆæ–‡åŒ–èƒŒæ™¯ï¼‰ã€‚
- CBSâ‰ˆ50%è¡¨ç¤ºæ¨¡å‹å¯¹ä¸¤è¾¹éƒ½å·®ä¸å¤šã€‚

CBSï¼ˆCultural Bias Scoreï¼‰= 1è¡¨ç¤ºå…¨é€‰è¥¿æ–¹ï¼Œ0è¡¨ç¤ºå…¨é€‰é˜¿æ‹‰ä¼¯ã€‚


âœ… **LMsæ™®éåå‘è¥¿æ–¹å®ä½“**ï¼ˆå³ä½¿æç¤ºæ˜ç¡®æ˜¯é˜¿æ‹‰ä¼¯æ–‡åŒ–ï¼‰ï¼ŒCBSé«˜è¾¾40-60%ï¼Œå’Œä¸­ç«‹ä¸Šä¸‹æ–‡é‡Œè¡¨ç°å·®ä¸å¤šï¼Œè¯´æ˜æ¨¡å‹æ–‡åŒ–é€‚åº”æ€§å¼±ã€‚  
âœ… **å•è¯­é˜¿æ‹‰ä¼¯æ¨¡å‹ä¹Ÿæœ‰è¥¿æ–¹åè§**ï¼Œå¯èƒ½æ˜¯å› ä¸ºé¢„è®­ç»ƒæ•°æ®åå‘è¥¿æ–¹è¯é¢˜ã€‚  
âœ… **å¤šè¯­ç§æ¨¡å‹åè§æ›´ä¸¥é‡**ï¼Œå¤šè¯­è¨€è®­ç»ƒæ—¶å¾€å¾€å¼ºåŒ–äº†è‹±è¯­ï¼ˆè¥¿æ–¹ï¼‰ä¸»å¯¼çš„æ–‡åŒ–ã€‚  
âœ… **Prompt AdaptationæŠ€å·§ï¼ˆN-shot Demosï¼‰å¯ä»¥æ”¹å–„æ–‡åŒ–é€‚åº”æ€§**ï¼ŒCulture Tokenæ•ˆæœä¸å¤§ã€‚

###  Analyzing Arabic Pre-training Data

  the observed failures of LMs in appropriate cultural adaptation could be the prevalence of Western content in the Arabic pretraining corpora. To gain more insight, we analyze six Arabic corpora that are commonly used in pretraining LMs, comparing their cultural relevance.

è¯­è¨€æ¨¡å‹åœ¨é€‚å½“æ–‡åŒ–é€‚åº”æ–¹é¢çš„å¤±è´¥ï¼Œå¯èƒ½æºäºé˜¿æ‹‰ä¼¯è¯­é¢„è®­ç»ƒè¯­æ–™åº“ä¸­è¥¿æ–¹å†…å®¹çš„æ™®éæ€§ã€‚ä¸ºäº†è·å¾—æ›´æ·±å…¥çš„è§è§£ï¼Œæˆ‘ä»¬åˆ†æäº†å…­ç§å¸¸ç”¨äºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„é˜¿æ‹‰ä¼¯è¯­è¯­æ–™åº“ï¼Œå¹¶å¯¹æ¯”äº†å®ƒä»¬çš„æ–‡åŒ–ç›¸å…³æ€§ã€‚



==Local news and Twitter/X corpora had the lowest CBS, suggesting that future work may consider these sources for training more culturally adapted LMs.==
æœ¬åœ°æ–°é—»å’ŒTwitter/Xè¯­æ–™åº“çš„CBSæœ€ä½ï¼Œè¿™è¡¨æ˜æœªæ¥çš„å·¥ä½œå¯ä»¥è€ƒè™‘è¿™äº›æ¥æºæ¥è®­ç»ƒæ›´å…·æ–‡åŒ–é€‚åº”æ€§çš„è¯­è¨€æ¨¡å‹ã€‚


## Limitations

- Focused only on Arabic vs. Western cultural contexts.
    
- No evaluation of sub-regional or intra-cultural variations (e.g., within the Arab world).
    
- Primarily lexicon-level analysis, without assessing stylistic or deeper semantic features.
    
- Data limited to Twitter/X contexts; other platforms might exhibit different biases.



## Additional 

### n-gram LMs

### Arabic Grammar

In Arabic, verbs are conjugated to reflect gender (male or female) and number (singular, dual, or plural) of the subject.

åœ¨é˜¿æ‹‰ä¼¯è¯­é‡Œï¼ŒåŠ¨è¯åœ¨ä½¿ç”¨æ—¶å¿…é¡»æ ¹æ®ä¸»è¯­çš„â€œæ€§åˆ«ï¼ˆç”·æ€§æˆ–å¥³æ€§ï¼‰â€ä»¥åŠâ€œæ•°ï¼ˆå•æ•°ã€åŒæ•°æˆ–å¤æ•°ï¼‰â€è¿›è¡Œå˜åŒ–ã€‚æ¢å¥è¯è¯´ï¼ŒåŠ¨è¯çš„å½¢å¼ä¼šæ ¹æ®â€œè°åœ¨åšåŠ¨ä½œâ€è€Œå‘ç”Ÿå˜åŒ–ã€‚
#### ğŸŒŸ ä¸¾ä¸ªä¾‹å­ï¼š

å‡è®¾åŠ¨è¯æ˜¯â€œå†™â€ï¼ˆå†™ä½œï¼‰â€”â€”åœ¨é˜¿æ‹‰ä¼¯è¯­é‡Œæ˜¯ â€œÙŠÙƒØªØ¨â€ (yaktubu, â€œhe writesâ€)ã€‚

- å¦‚æœä¸»è¯­æ˜¯å•æ•°ç”·æ€§ï¼Œå°±ç”¨ â€œ ÙŠÙƒØªØ¨Ù â€ (yaktubu)
    
- å¦‚æœä¸»è¯­æ˜¯å•æ•°å¥³æ€§ï¼Œå°±ç”¨ â€œ ØªÙƒØªØ¨Ù â€ (taktubu)
    
- å¦‚æœä¸»è¯­æ˜¯åŒæ•°ç”·æ€§ï¼Œå°±ç”¨ â€œ ÙŠÙƒØªØ¨Ø§Ù† â€ (yaktubÄni)
    
- å¦‚æœä¸»è¯­æ˜¯åŒæ•°å¥³æ€§ï¼Œå°±ç”¨ â€œ ØªÙƒØªØ¨Ø§Ù† â€ (taktubÄni)
    
- å¦‚æœä¸»è¯­æ˜¯å¤æ•°ç”·æ€§ï¼Œå°±ç”¨ â€œ ÙŠÙƒØªØ¨ÙˆÙ† â€ (yaktubÅ«na)
    
- å¦‚æœä¸»è¯­æ˜¯å¤æ•°å¥³æ€§ï¼Œå°±ç”¨ â€œ ÙŠÙƒØªØ¨Ù† â€ (yaktubna)
    

ğŸ‘‰ è¿™æ ·ä¸€æ¥ï¼ŒåŠ¨è¯çš„è¯å°¾æˆ–è€…å‰ç¼€éƒ½ä¼šéšç€ä¸»è¯­çš„æ€§åˆ«å’Œæ•°è€Œå‘ç”Ÿå˜åŒ–ã€‚è¿™æ˜¯é˜¿æ‹‰ä¼¯è¯­çš„ä¸€ä¸ªè¯­æ³•ç‰¹ç‚¹ã€‚

---
## Farasa POS tagger & Odds Ratio (OR)

we analyze the frequency of adjective usage by LMs in the stories featuring Arab or Western names. To do so, we extract all adjectives from stories using the Farasa POS tagger (Abdelali et al., 2016) and compute their Odds Ratio (OR) (Wan et al., 2023)
æˆ‘ä»¬åˆ†æäº†åœ¨åŒ…å«é˜¿æ‹‰ä¼¯æˆ–è¥¿æ–¹åå­—çš„æ•…äº‹ä¸­ï¼Œè¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰ä½¿ç”¨å½¢å®¹è¯çš„é¢‘ç‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ©ç”¨æ³•æ‹‰è¨è¯æ€§æ ‡æ³¨å™¨ä»æ•…äº‹ä¸­æå–æ‰€æœ‰å½¢å®¹è¯ï¼Œå¹¶è®¡ç®—å…¶ä¼˜åŠ¿æ¯”ï¼ˆORï¼‰ã€‚

Farasa æ˜¯ä¸€ä¸ª**é˜¿æ‹‰ä¼¯è¯­çš„è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·**ï¼Œç”¨äºåˆ†è¯å’Œè¯æ€§æ ‡æ³¨ã€‚OR ç”¨æ¥è¡¡é‡æŸä¸ªå½¢å®¹è¯åœ¨è¥¿æ–¹æˆ–é˜¿æ‹‰ä¼¯åå­—æ•…äº‹ä¸­å‡ºç°çš„ç›¸å¯¹å¯èƒ½æ€§ã€‚

OR æ˜¯å¸¸ç”¨çš„æ¦‚ç‡æ¯”æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡æŸäº‹ä»¶åœ¨ä¸¤ç»„ä¸­çš„ç›¸å¯¹å¯èƒ½æ€§ã€‚  
å…¬å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š

OR = äº‹ä»¶åœ¨è¥¿æ–¹æ•…äº‹ä¸­å‡ºç°çš„æ¦‚ç‡â€‹ / äº‹ä»¶åœ¨é˜¿æ‹‰ä¼¯æ•…äº‹ä¸­å‡ºç°çš„æ¦‚ç‡

ORå€¼å¤§ï¼Œè¡¨ç¤ºæŸä¸ªå½¢å®¹è¯æ›´æœ‰å¯èƒ½å‡ºç°åœ¨è¥¿æ–¹åå­—çš„æ•…äº‹ä¸­ï¼›ORå€¼å°ï¼Œè¡¨ç¤ºæ›´æœ‰å¯èƒ½å‡ºç°åœ¨é˜¿æ‹‰ä¼¯åå­—çš„æ•…äº‹ä¸­ã€‚**é€šè¿‡ORå€¼å¯ä»¥é‡åŒ–æ¨¡å‹åœ¨ç”Ÿæˆæ•…äº‹æ—¶çš„æ–‡åŒ–åè§ã€‚**


æˆ‘ä»¬æŒ‘é€‰å‡ºORå€¼æœ€é«˜å’Œæœ€ä½çš„å‰50ä¸ªå½¢å®¹è¯ï¼Œæ ¹æ®Caoç­‰ï¼ˆ2022aï¼‰çš„ç ”ç©¶ï¼Œåˆ©ç”¨**Agency-Belief Communion (ABC)** æ¡†æ¶ï¼ˆKochç­‰ï¼Œ2016ï¼‰å°†è¿™äº›å½¢å®¹è¯æŒ‰åˆ»æ¿å°è±¡è¿›è¡Œåˆ†ç±»ï¼ˆå¦‚è´«ç©·ã€å—æ¬¢è¿ç­‰ï¼‰ã€‚

ç”¨ABCæ¡†æ¶å¯¹å½¢å®¹è¯è¿›è¡Œåˆ»æ¿å°è±¡çš„æ ‡ç­¾åŒ–ï¼Œæ¯”å¦‚ï¼š

- Agencyï¼ˆèƒ½åŠ¨æ€§ï¼‰ï¼šå¯Œæœ‰ã€ä¸Šè¿›
- Beliefï¼ˆä¿¡å¿µ/ä»·å€¼è§‚ï¼‰ï¼šä¼ ç»Ÿã€å®—æ•™
- Communionï¼ˆå…³ç³»æ€§ï¼‰ï¼šå‹å–„ã€å—æ¬¢è¿

è¿™æ ·å°±å¯ä»¥åˆ†ææ¨¡å‹æ˜¯ä¸æ˜¯åœ¨æ½œæ„è¯†ä¸­æŠŠé˜¿æ‹‰ä¼¯è§’è‰²è´´ä¸Šäº†â€œç©·è‹¦â€ã€â€œä¿å®ˆâ€ç­‰æ ‡ç­¾ï¼Œè€ŒæŠŠè¥¿æ–¹è§’è‰²è´´ä¸Šäº†â€œå¯Œè£•â€ã€â€œå¼€æ˜â€ç­‰æ ‡ç­¾ã€‚

---

## Likelihood-based scoring

å°±æ˜¯å¯¹æ¨¡å‹é¢„æµ‹çš„tokenï¼ˆå€™é€‰å®ä½“ï¼‰æ¦‚ç‡è¿›è¡Œæ¯”è¾ƒï¼Œçœ‹æ¨¡å‹æ›´å€¾å‘äºç”Ÿæˆå“ªä¸€ä¸ªã€‚è¿™æ˜¯æµ‹è¯•æ¨¡å‹â€œå€¾å‘æ€§â€çš„å¸¸ç”¨æ–¹æ³•ã€‚


## Text Infilling

åœ¨ `[MASK]` å¤„è®©æ¨¡å‹å¡«ç©ºã€‚BERTç­‰MLMæ¨¡å‹æ˜¯å¤©ç„¶æ”¯æŒçš„ï¼ˆç›´æ¥è®¡ç®—æ¦‚ç‡ï¼‰ï¼ŒGPT/T5ç­‰å› è‡ªå›å½’ç»“æ„ï¼Œéœ€è¦ç¨ä½œä¿®æ”¹ï¼Œæ¯”å¦‚åªçœ‹æç¤ºå‰çš„ä¸Šä¸‹æ–‡ã€‚



## å¥½è¯å¥½å¥

	reach v. åˆ°è¾¾ï¼›å®ç°ï¼Œè¾¾åˆ°ï¼›å¼•èµ·æ³¨æ„ï¼›ä¼¸æ‰‹ï¼Œå¤Ÿå¾—ç€ï¼›è”ç³» n. è‡‚å±•ï¼›å½±å“èŒƒå›´ï¼›æ²³æ®µï¼›è¾¹è¿œåœ°åŒºï¼›é¢†åŸŸ
		As the reach of large language models,... éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ™®åŠ
	in light of adv. æŒ‰ç…§ï¼Œæ ¹æ®
		In light of the global deployment of LMs, it is crucial to ensure these models grasp the cultural distinctions of diverse communities. é‰´äºè¯­è¨€æ¨¡å‹åœ¨å…¨çƒçš„éƒ¨ç½²ï¼Œç¡®ä¿è¿™äº›æ¨¡å‹æŒæ¡ä¸åŒç¤¾åŒºçš„æ–‡åŒ–å·®å¼‚è‡³å…³é‡è¦ã€‚
	grasp  v. æŠ“ç´§ï¼›ç†è§£ï¼›æ€¥å¿™æŠ“ä½ n. ç´§æŠ“ï¼›æŒæ¡ï¼›ç†è§£ï¼›åŠ›æ‰€èƒ½åŠ
	bridge n. æ¡¥ï¼ˆæ¢ï¼‰ï¼›çº½å¸¦ï¼›é¼»æ¢ï¼ˆæ¶ï¼‰ï¼›æ¡¥ç‰Œï¼›ç´é©¬ï¼›é½¿æ¡¥ v. å¼¥åˆï¼Œæ¶ˆé™¤ï¼›å…¼å…·â€¦çš„ç‰¹ç‚¹ï¼›åœ¨â€¦ä¸Šæ¶æ¡¥
		Despite progress to bridge the language barrier gap, LMs still struggle at capturing cultural nuances and adapting to specific cultural contexts. å°½ç®¡åœ¨å…‹æœè¯­è¨€éšœç¢æ–¹é¢å·²å–å¾—è¿›å±•ï¼Œä½†è¯­è¨€æ¨¡å‹åœ¨æ•æ‰æ–‡åŒ–ç»†å¾®å·®åˆ«å’Œé€‚åº”ç‰¹å®šæ–‡åŒ–èƒŒæ™¯æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚
	foster v. åŸ¹å…»ï¼Œä¿ƒè¿›ï¼›æ”¶å…»ï¼Œå…»è‚²
		foster a deeper global connection.
	completion n.c. å®Œæˆï¼›ç»“æŸï¼›ï¼ˆæˆ¿åœ°äº§ç­‰çš„ï¼‰å®Œæˆäº¤æ˜“ï¼›å®Œæˆäº¤å‰²ï¼›è¡¥å……
		LMs fail at appropriate cultural adaptation in Arabic when asked to provide completions to various prompts, often suggesting and prioritizing Western-centric content. å½“è¦æ±‚LMså¯¹å„ç§æç¤ºè¿›è¡Œè¡¥å……æ—¶ï¼Œå®ƒä»¬åœ¨é˜¿æ‹‰ä¼¯è¯­ä¸­æ— æ³•è¿›è¡Œé€‚å½“çš„æ–‡åŒ–é€‚åº”ï¼Œé€šå¸¸ä¼šæå‡ºä»¥è¥¿æ–¹ä¸ºä¸­å¿ƒçš„å†…å®¹å¹¶ä¼˜å…ˆè€ƒè™‘ã€‚
	prayer  n. ç¥ˆç¥·ï¼›ç¥·è¯ï¼›ç¥ˆæœ›ï¼›ç¥ˆç¥·ä»ªå¼
	predominantly adv. å ä¸»å¯¼åœ°ä½åœ°ï¼›æ˜¾è‘—åœ°ï¼›å ä¼˜åŠ¿åœ°
		in the predominantly Muslim Arab world
	prevalent adj. æµè¡Œçš„ï¼Œç››è¡Œçš„ï¼›æ™®éå­˜åœ¨çš„ï¼Œæ™®éå‘ç”Ÿçš„
	inadequate /inËˆadÉ™kwÉ™t/ adj. ä¸å……è¶³çš„ï¼›ä¸é€‚å½“çš„ï¼›ä¸è¶³èƒœä»»çš„ï¼›ä¿¡å¿ƒä¸è¶³çš„
		user may find it upsetting to see inadequate cultural representation by LMs in their own languages. ç”¨æˆ·å¯èƒ½ä¼šå› ä¸ºçœ‹åˆ°è‡ªå·±çš„è¯­è¨€ä¸­LMsçš„æ–‡åŒ–ä»£è¡¨æ€§ä¸è¶³è€Œæ„Ÿåˆ°ä¸å®‰ã€‚
	demographic adj. äººå£ï¼ˆå­¦ï¼‰çš„ï¼›äººå£ç»Ÿè®¡ï¼ˆå­¦ï¼‰çš„ n. äººå£ç‰¹å¾ï¼Œäººå£ç»Ÿè®¡æ•°æ®ï¼›äººç¾¤
	considerable adj. ç›¸å½“å¤§/å¤šçš„
		considerable effort has gone into exploring biases in LMs
	religion  n. å®—æ•™ï¼›æ”¯é…è‡ªå·±ç”Ÿæ´»çš„å¤§äº‹ï¼›æ•™æ´¾ï¼›å¿ƒçˆ±çš„äº‹ç‰©
	cater  v. æ»¡è¶³â€¦çš„éœ€è¦ï¼›æ¥å¾…ï¼›è€ƒè™‘åˆ°ï¼›æä¾›é¥®é£Ÿï¼›æ‰¿åŠé…’å¸­
		their ability to cater to diverse cultural contexts becomes crucial.
	heritage /ËˆherÉ™dij/ n. é—äº§ï¼›ä¼ ç»Ÿ
		cultural heritage æ–‡åŒ–é—äº§
	versatile /ËˆvÉ™rsÉ™dl/ adj. ï¼ˆæŒ‡å·¥å…·ã€æœºå™¨ç­‰ï¼‰å¤šç”¨é€”çš„ï¼›å¤šæ‰å¤šè‰ºçš„ï¼›æœ‰å¤šç§å­¦é—®ã€æŠ€èƒ½æˆ–èŒä¸šçš„ï¼›å¤šåŠŸèƒ½çš„
		 We show that CAMeL entities and prompts enable cross-cultural testing of LMs in versatile experimental setups. æˆ‘ä»¬è¯æ˜äº†CAMeLå®ä½“å’Œæç¤ºèƒ½å¤Ÿåœ¨å¤šæ ·çš„å®éªŒè®¾ç½®ä¸­å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œè·¨æ–‡åŒ–æµ‹è¯•ã€‚
	stereotype /ËˆsterÄ“É™ËŒtaip/  n.c è€å¥—ï¼Œæ¨¡å¼åŒ–çš„è§è§£ï¼Œåˆ»æ¿å°è±¡ï¼Œæœ‰è€ä¸€å¥—å›ºå®šæƒ³æ³•çš„äºº v. æŠŠâ€¦æ¨¡å¼åŒ–ï¼Œä½¿æˆé™ˆè§„
		 cultural stereotypes  æ–‡åŒ–åˆ»æ¿å°è±¡ï¼Œæ–‡ä»¶å®šåŠ¿
	benchmark   n.c åŸºå‡†ï¼Œå‚ç…§ï¼›æ ‡å‡†æ£€æŸ¥ç¨‹åºï¼›æ°´å‡†æ ‡; v. è¿›è¡ŒåŸºå‡†æµ‹è¯•
		 We benchmark 16 LMs pre-trained with Arabic data. æˆ‘ä»¬å¯¹16ä¸ªä½¿ç”¨é˜¿æ‹‰ä¼¯è¯­æ•°æ®é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚
	proper nouns ä¸“æœ‰åè¯
	common nouns æ™®é€šåè¯
	gauge /É¡Äj/  n. æµ‹é‡çš„æ ‡å‡†æˆ–èŒƒå›´ï¼›å°ºåº¦ï¼Œæ ‡å‡†ï¼›æµ‹é‡ä»ªå™¨ï¼›è¯„ä¼° vt. ï¼ˆç”¨ä»ªå™¨ï¼‰æµ‹é‡ï¼›ç¡®å®šå®¹é‡ï¼Œä½“ç§¯æˆ–å†…å®¹ï¼›è¯„ä¼°ï¼Œåˆ¤æ–­ï¼›é‡‡ç”¨
	agnostic /aÉ¡ËˆnÃ¤stik/ n. ä¸å¯çŸ¥è®ºè€…
		culturally-agnostic æ–‡åŒ–ä¸­ç«‹çš„
	contextualize  v. å°†â€¦â€¦ç½®äºä¸Šä¸‹æ–‡ï¼ˆæˆ–èƒŒæ™¯ï¼‰ä¸­ç ”ç©¶
		culturally-contextualized æ–‡åŒ–èƒŒæ™¯åŒ–çš„
	spoil   n. <æ­£>æˆ˜åˆ©å“ï¼Œèµƒç‰© v. å˜è´¨ï¼›æŸåï¼›æ¯æ‰ï¼›ç ´å
	What X spoils, Y will fix ä¸€ä¸ªå…¸å‹çš„è‹±è¯­å¤åˆå¥ç»“æ„ï¼Œç”¨ä½œå¼ºè°ƒä¿®å¤ä¸å¼¥è¡¥ã€‚è¡¨ç¤ºï¼šX æŸæ¯çš„... / è®©...ç³Ÿç³•, Y ä¼šå¼¥è¡¥/ä¿®å¤ 
		What the world spoils, my Arab cooking skills will fix. æ— è®ºä¸–ç•Œè®©ä»€ä¹ˆå˜å¾—ç³Ÿç³•ï¼Œæˆ‘çš„é˜¿æ‹‰ä¼¯çƒ¹é¥ªéƒ½èƒ½è®©å®ƒå˜å¥½ã€‚
	mirror n. é•œå­ï¼Œåå…‰é•œï¼›çœŸå®çš„å†™ç…§ï¼›åæ˜ ï¼Œå€Ÿé‰´ï¼›æ¦œæ · vt. åæ˜ ï¼›åå°„
		 To ensure we evaluate LMs in scenarios that mirror actual language use ä¸ºäº†ç¡®ä¿æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿ/åæ˜ å®é™…è¯­è¨€ä½¿ç”¨çš„åœºæ™¯ä¸­è¯„ä¼°è¯­è¨€æ¨¡å‹
	portray v. ç”»åƒï¼›æè¿°ï¼›æç»˜ï¼›æç”»
	treat v. å¯¹å¾…ï¼Œæ²»ç–—ã€‚ n. an event or item that is out of the ordinary and gives great pleasure. æ¬¾å¾…ï¼Œäº«å—ï¼Œè®©äººæ„Ÿåˆ°å¿«ä¹çš„äº‹æƒ…
		Learning about how those classes made a lasting impact is a treat. äº†è§£è¿™äº›è¯¾ç¨‹å¦‚ä½•äº§ç”ŸæŒä¹…çš„å½±å“ï¼ŒçœŸæ˜¯ä¸€ç§äº«å—ã€‚
	recipe /ËˆresÉ™ËŒpÄ“/ n.c. é£Ÿè°± a set of instructions for preparing a particular dish, including a list of the ingredients required.
	odd adj. å¥‡æ€ªçš„ï¼Œå•çš„ï¼Œå¶ç„¶çš„ï¼Œå¼‚å¸¸çš„
		odd number å¥‡æ•°ï¼Œ å•æ•°
	odds n. èµ”ç‡ï¼Œå¯èƒ½æ€§ï¼Œæ¦‚ç‡ã€‚the ratio between the amounts staked by the parties to a bet, based on the expected probability either way.
	vanilla  n. é¦™å­å…°ï¼Œé¦™è‰ï¼›é¦™å­å…°èšï¼›é¦™å­å…°ç²¾ï¼Œé¦™è‰ç²¾ adj. é¦™è‰çš„ï¼›é¦™è‰å‘³çš„ï¼›ç›¸å¯¹æ²¡æœ‰æ–°æ„çš„ï¼Œæ™®é€šçš„